% https://www.overleaf.com/learn/latex/Beamer#Introduction
% https://en.wikibooks.org/wiki/LaTeX/Presentations#The_Beamer_package
\documentclass{beamer}
\usepackage[utf8]{inputenc}
% http://texblog.net/latex-archive/latex-general/beamer-warnings/
\usepackage{lmodern}
% https://hartwork.org/beamer-theme-matrix/
% \usecolortheme{dove}

% https://tex.stackexchange.com/a/356169
\usepackage[style=ieee,backend=bibtex]{biblatex}
\addbibresource{bibliography.bib}

\beamertemplatenavigationsymbolsempty
% https://tex.stackexchange.com/a/74251
\setbeamerfont{page number in head/foot}{size=\small}
\setbeamertemplate{footline}[frame number]
\setbeamerfont{footnote}{size=\tiny}
 
\author{Russel Shawn Dsouza}
% https://tex.stackexchange.com/a/61053
\institute
{
  \includegraphics[scale=0.25]{images/logo}\\
  Electronics and Communications Engg.\\
  National Institute of Technology Karnataka\\
  Surathkal, India - 575025
}
\date{October 9, 2019}

\title[Neural TTS]{Neural Text-to-Speech}
% \subtitle{A short story}
 
\begin{document}

  % https://stackoverflow.com/a/54916411
  \begingroup
    \setbeamertemplate{footline}{}
    \frame{\titlepage}
  \endgroup

  \addtocounter{framenumber}{-1}

  % https://tex.stackexchange.com/a/198102
  % \begin{frame}{Overview}
  %   \tableofcontents
  % \end{frame}

  \begin{frame}
    \frametitle{Speech synthesis}
      Artificial production of human speech
      \begin{figure}
        \centering
        \includegraphics[width=\textwidth]{images/TTS_System_screenshot}
        \caption{A typical text-to-speech system\footfullcite{wiki_tts}}
      \end{figure}
  \end{frame}

  \begin{frame}
    \frametitle{History of speech synthesis}
    % TODO: Add images for each type
      \begin{columns}
        \column{0.5\textwidth}
          \centering
          \textbf{Concatenative}\\
          \begin{itemize}
            \item Large database of human speech used
          \end{itemize}

        \column{0.5\textwidth}
          \centering
          \textbf{Parametric}\\
          \begin{itemize}
            \item Simulate human voice using a function
          \end{itemize}

          \textbf{Neural}\\
          \begin{itemize}
            \item Generate human voice using neural networks
          \end{itemize}
      \end{columns}
  \end{frame}

  \begin{frame}
    \frametitle{Approaches in Neural text-to-speech}
      % TODO: Add images for each type
      % TODO: Add text
      \begin{columns}
        \column{0.33\textwidth}
          LSTM
        \column{0.33\textwidth}
          WaveNet
        \column{0.33\textwidth}
          WaveNet based
      \end{columns}
  \end{frame}

  \begin{frame}
    \frametitle{WaveNet}
      A deep neural network for generating raw audiowaveforms.

      \begin{itemize}
        \item Probabilistic 
        \item Autoregressive
        \item Beats all previously known methods
      \end{itemize}
      \begin{figure}
        \centering
        \includegraphics[width=\textwidth]{images/second_of_speech.png}
        \caption{Time domain representation of 1 second of generated speech}
      \end{figure}
  \end{frame}

  \begin{frame}
    \frametitle{WaveNet: Architecture}
      \begin{itemize}
        \item Dilated convolution
        \item $\mu$ law companding
        \item Gated activation
        \item Residual and skip connection
        \item Conditional wavenets
        \item Context stacks
      \end{itemize}
  \end{frame}

  \begin{frame}
    \frametitle{1. Dilated Convolution}
    \begin{figure}
      \includegraphics[scale=0.22]{images/wavenet_arch_dilated_conv.png}
      \caption{Stack of dilated causal convolution layers\footfullcite{oord_wavenet:_2016}}
    \end{figure}
  \end{frame}

  \begin{frame}
    \frametitle{2. $\mu$-law companding}
    \centering
    % TODO: Explain equation
    \begin{equation*}
      f(x_t) = \text{sign}(x_t)\frac{\ln(1 + \mu|x_t|)}{\ln(1 + \mu)}
    \end{equation*}
    where, $x_t$ is the time domain speech signal
  \end{frame}

  \begin{frame}
    \frametitle{3. Gated activation}
    \centering
    % TODO: Explain equation
    \begin{equation*}
      \mathbf{z} = \tanh(W_{f, k}*\mathbf{x}) \circledast \sigma (W_{g, k}*\mathbf{x})
    \end{equation*}
  \end{frame}

  \begin{frame}
    \frametitle{4. Residual and skip connections}
    \begin{figure}[ht]
      \includegraphics[width=\textwidth]{images/wavenet_arch_residual.png}
      \caption{Overview of residual block and entire architecture \footfullcite{oord_wavenet:_2016}}
    \end{figure}
  \end{frame}

  \begin{frame}
    \frametitle{5. Conditional WaveNets}
    % TODO: Explain equation
    \begin{equation*}
      p(\mathbf{x} | \mathbf{h}) = \prod_{t=1}^{T}p(x_t | x_1, \ldots, x_{t-1}, \mathbf{h}) 
    \end{equation*}
  \end{frame}

  \begin{frame}
    \frametitle{6. Context Stacks}
      % TODO: Explain this
  \end{frame}

  \begin{frame}
    \frametitle{WaveNet: Pros and Cons}
    \begin{columns}
      \column{0.5\textwidth}
        \textbf{Pros}
        \begin{itemize}
          \item Fast training
        \end{itemize}
      \column{0.5\textwidth}
        \textbf{Cons}
        \begin{itemize}
          \item Slow inference
        \end{itemize}
    \end{columns}
  \end{frame}

  \begin{frame}
    \frametitle{Tacotron 2}
  \end{frame}

  \begin{frame}
    \frametitle{Tacotron 2: Architecture}
  \end{frame}

  \begin{frame}
    \frametitle{Tacotron 2: Training}
  \end{frame}

  \begin{frame}
    \frametitle{Tacotron 2: Reported results}
  \end{frame}

  \begin{frame}
    \frametitle{Tacotron 2: Improvements over WaveNet}
  \end{frame}

  \begin{frame}
    \frametitle{Neural TTS: The future}
  \end{frame}

  \begin{frame}
    \frametitle{Summary}
  \end{frame}

  \begin{frame}
    \frametitle{Conclusion}
  \end{frame}
  
\end{document}
